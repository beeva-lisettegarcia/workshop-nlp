{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Freeling\n",
    "\n",
    "* *Página web:* http://nlp.cs.upc.edu/freeling/\n",
    "* *Consejos de instalación:* https://medium.com/@cristhian.fuertes/installation-of-freeling-with-python-7407797f5afd#.r0meg9dg0\n",
    "* *Lista de clases:* http://nlp.lsi.upc.edu/freeling/doc/refman/annotated.html\n",
    "* *Tagset:* http://nlp.lsi.upc.edu/freeling-old/doc/tagsets/tagset-es.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#! /usr/bin/python3\n",
    "\n",
    "\n",
    "\n",
    "import freeling\n",
    "import sys\n",
    "\n",
    "## ------------  output a parse tree ------------\n",
    "def printTree(ptree, depth):\n",
    "\n",
    "    node = ptree.begin();\n",
    "\n",
    "    print(''.rjust(depth*2),end='');\n",
    "    info = node.get_info();\n",
    "    if (info.is_head()): print('+',end='');\n",
    "\n",
    "    nch = node.num_children();\n",
    "    if (nch == 0) :\n",
    "        w = info.get_word();\n",
    "        print ('({0} {1} {2})'.format(w.get_form(), w.get_lemma(), w.get_tag()),end='');\n",
    "\n",
    "    else :\n",
    "        print('{0}_['.format(info.get_label()));\n",
    "\n",
    "        for i in range(nch) :\n",
    "            child = node.nth_child_ref(i);\n",
    "            printTree(child, depth+1);\n",
    "\n",
    "        print(''.rjust(depth*2),end='');\n",
    "        print(']',end='');\n",
    "        \n",
    "    print('');\n",
    "\n",
    "## ------------  output a parse tree ------------\n",
    "def printDepTree(dtree, depth):\n",
    "\n",
    "    node = dtree.begin()\n",
    "\n",
    "    print(''.rjust(depth*2),end='');\n",
    "\n",
    "    info = node.get_info();\n",
    "    link = info.get_link();\n",
    "    linfo = link.get_info();\n",
    "    print ('{0}/{1}/'.format(link.get_info().get_label(), info.get_label()),end='');\n",
    "\n",
    "    w = node.get_info().get_word();\n",
    "    print ('({0} {1} {2})'.format(w.get_form(), w.get_lemma(), w.get_tag()),end='');\n",
    "\n",
    "    nch = node.num_children();\n",
    "    if (nch > 0) :\n",
    "        print(' [');\n",
    "\n",
    "        for i in range(nch) :\n",
    "            d = node.nth_child_ref(i);\n",
    "            if (not d.begin().get_info().is_chunk()) :\n",
    "                printDepTree(d, depth+1);\n",
    "\n",
    "        ch = {};\n",
    "        for i in range(nch) :\n",
    "            d = node.nth_child_ref(i);\n",
    "            if (d.begin().get_info().is_chunk()) :\n",
    "                ch[d.begin().get_info().get_chunk_ord()] = d;\n",
    " \n",
    "        for i in sorted(ch.keys()) :\n",
    "            printDepTree(ch[i], depth + 1);\n",
    "\n",
    "        print(''.rjust(depth*2),end='');\n",
    "        print(']',end='');\n",
    "\n",
    "    print('');\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Modify this line to be your FreeLing installation directory\n",
    "FREELINGDIR = \"/usr/local\";\n",
    "\n",
    "DATA = FREELINGDIR+\"/share/freeling/\";\n",
    "LANG=\"es\";\n",
    "\n",
    "freeling.util_init_locale(\"default\");\n",
    "\n",
    "# create language analyzer\n",
    "la=freeling.lang_ident(DATA+\"common/lang_ident/ident.dat\");\n",
    "\n",
    "# create options set for maco analyzer. Default values are Ok, except for data files.\n",
    "op= freeling.maco_options(\"es\");\n",
    "op.set_data_files( \"\", \n",
    "                   DATA + \"common/punct.dat\",\n",
    "                   DATA + LANG + \"/dicc.src\",\n",
    "                   DATA + LANG + \"/afixos.dat\",\n",
    "                   \"\",\n",
    "                   DATA + LANG + \"/locucions.dat\", \n",
    "                   DATA + LANG + \"/np.dat\",\n",
    "                   DATA + LANG + \"/quantities.dat\",\n",
    "                   DATA + LANG + \"/probabilitats.dat\");\n",
    "\n",
    "# create analyzers\n",
    "tk=freeling.tokenizer(DATA+LANG+\"/tokenizer.dat\");\n",
    "sp=freeling.splitter(DATA+LANG+\"/splitter.dat\");\n",
    "sid=sp.open_session();\n",
    "mf=freeling.maco(op);\n",
    "\n",
    "# activate mmorpho odules to be used in next call\n",
    "mf.set_active_options(False, True, True, True,  # select which among created \n",
    "                      True, True, False, True,  # submodules are to be used. \n",
    "                      True, True, True, True ); # default: all created submodules are used\n",
    "\n",
    "# create tagger, sense anotator, and parsers\n",
    "tg=freeling.hmm_tagger(DATA+LANG+\"/tagger.dat\",True,2);\n",
    "sen=freeling.senses(DATA+LANG+\"/senses.dat\");\n",
    "parser= freeling.chart_parser(DATA+LANG+\"/chunker/grammar-chunk.dat\");\n",
    "dep=freeling.dep_txala(DATA+LANG+\"/dep_txala/dependences.dat\", parser.get_start_symbol());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Texto a analizar\n",
    "\n",
    "text = \"El perro ha saltado la valla. Estoy preocupada, quizás se pierda o ataque a alguien.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El\n",
      "perro\n",
      "ha\n",
      "saltado\n",
      "la\n",
      "valla\n",
      ".\n",
      "Estoy\n",
      "preocupada\n",
      ",\n",
      "quizás\n",
      "se\n",
      "pierda\n",
      "o\n",
      "ataque\n",
      "a\n",
      "alguien\n",
      ".\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Separa palabras\n",
    "\n",
    "l = tk.tokenize(text);\n",
    "for w in l:\n",
    "    print(w.get_form())\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***sentence 1***\n",
      "El\n",
      "perro\n",
      "ha\n",
      "saltado\n",
      "la\n",
      "valla\n",
      ".\n",
      "\n",
      "***sentence 2***\n",
      "Estoy\n",
      "preocupada\n",
      ",\n",
      "quizás\n",
      "se\n",
      "pierda\n",
      "o\n",
      "ataque\n",
      "a\n",
      "alguien\n",
      ".\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Separa oraciones\n",
    "\n",
    "ls = sp.split(sid, l, False);\n",
    "idx = 1\n",
    "for s in ls:\n",
    "    ws = s.get_words();\n",
    "    print('***sentence'+' '+str(idx)+'***')\n",
    "    for w in ws :\n",
    "        print(w.get_form())\n",
    "    print()\n",
    "    idx += 1\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***sentence 1***\n",
      "El el DA0MS0\n",
      "perro perro NCMS000\n",
      "ha haber VAIP3S0\n",
      "saltado saltar VMP00SM\n",
      "la el DA0FS0\n",
      "valla valla NCFS000\n",
      ". . Fp\n",
      "\n",
      "***sentence 2***\n",
      "Estoy estar VMIP1S0\n",
      "preocupada preocupar VMP00SF\n",
      ", , Fc\n",
      "quizás quizás RG\n",
      "se se P00CN00\n",
      "pierda perder VMM03S0\n",
      "o o CC\n",
      "ataque ataque NCMS000\n",
      "a a SP\n",
      "alguien alguien PI0CS00\n",
      ". . Fp\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Análisis morfológico\n",
    "# (se supone que este análisis devuelva todas las opciones posibles de lema-tag, pero no encuentro la forma de mostralas todas)\n",
    "\n",
    "ls = mf.analyze(ls);\n",
    "idx = 1\n",
    "for s in ls:\n",
    "    ws = s.get_words();\n",
    "    print('***sentence'+' '+str(idx)+'***')\n",
    "    for w in ws :\n",
    "        print(w.get_form()+\" \"+w.get_lemma()+\" \"+w.get_tag())\n",
    "    print()\n",
    "    idx += 1\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***sentence 1***\n",
      "El el DA0MS0\n",
      "perro perro NCMS000\n",
      "ha haber VAIP3S0\n",
      "saltado saltar VMP00SM\n",
      "la el DA0FS0\n",
      "valla valla NCFS000\n",
      ". . Fp\n",
      "\n",
      "***sentence 2***\n",
      "Estoy estar VMIP1S0\n",
      "preocupada preocupar VMP00SF\n",
      ", , Fc\n",
      "quizás quizás RG\n",
      "se se P00CN00\n",
      "pierda perder VMSP3S0\n",
      "o o CC\n",
      "ataque atacar VMSP3S0\n",
      "a a SP\n",
      "alguien alguien PI0CS00\n",
      ". . Fp\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#POS tagging\n",
    "#desambigua, es decir, selecciona el lema y tag correcto según el contexto\n",
    "\n",
    "ls = tg.analyze(ls);\n",
    "idx = 1\n",
    "for s in ls:\n",
    "    ws = s.get_words();\n",
    "    print('***sentence'+' '+str(idx)+'***')\n",
    "    for w in ws :\n",
    "        print(w.get_form()+\" \"+w.get_lemma()+\" \"+w.get_tag())\n",
    "    print()\n",
    "    idx += 1\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***sentence 1***\n",
      "El el DA0MS0 \n",
      "perro perro NCMS000 02084071-n:0/10539715-n:0\n",
      "ha haber VAIP3S0 02603699-v:0/02655135-v:0\n",
      "saltado saltar VMP00SM 00256369-v:0/00616498-v:0/01236941-v:0/01892608-v:0/01910373-v:0/01963942-v:0/01965654-v:0/02081946-v:0/02094922-v:0/02095060-v:0/02095211-v:0\n",
      "la el DA0FS0 \n",
      "valla valla NCFS000 \n",
      ". . Fp \n",
      "\n",
      "***sentence 2***\n",
      "Estoy estar VMIP1S0 02655135-v:0/02729963-v:0\n",
      "preocupada preocupar VMP00SF 01765908-v:0/01767163-v:0/01783394-v:0/02678438-v:0\n",
      ", , Fc \n",
      "quizás quizás RG \n",
      "se se P00CN00 \n",
      "pierda perder VMSP3S0 00059769-v:0/01099592-v:0/01113806-v:0/02022659-v:0/02127853-v:0/02197091-v:0/02287618-v:0/02287789-v:0/02288155-v:0/02288828-v:0/02303331-v:0\n",
      "o o CC \n",
      "ataque atacar VMSP3S0 00019792-v:0/00862683-v:0/01118449-v:0/01119169-v:0/01120069-v:0\n",
      "a a SP \n",
      "alguien alguien PI0CS00 \n",
      ". . Fp \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Sentidos\n",
    "\n",
    "ls = sen.analyze(ls);\n",
    "idx = 1\n",
    "for s in ls:\n",
    "    ws = s.get_words();\n",
    "    print('***sentence'+' '+str(idx)+'***')\n",
    "    for w in ws :\n",
    "        print(w.get_form()+\" \"+w.get_lemma()+\" \"+w.get_tag()+\" \"+w.get_senses_string())\n",
    "    print()\n",
    "    idx += 1\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S_[\n",
      "  sn_[\n",
      "    espec-ms_[\n",
      "      +j-ms_[\n",
      "        +(El el DA0MS0)\n",
      "      ]\n",
      "    ]\n",
      "    +grup-nom-ms_[\n",
      "      +n-ms_[\n",
      "        +(perro perro NCMS000)\n",
      "      ]\n",
      "    ]\n",
      "  ]\n",
      "  grup-verb_[\n",
      "    +verb_[\n",
      "      vaux_[\n",
      "        +(ha haber VAIP3S0)\n",
      "      ]\n",
      "      +parti_[\n",
      "        +(saltado saltar VMP00SM)\n",
      "      ]\n",
      "    ]\n",
      "  ]\n",
      "  sn_[\n",
      "    espec-fs_[\n",
      "      +j-fs_[\n",
      "        +(la el DA0FS0)\n",
      "      ]\n",
      "    ]\n",
      "    +grup-nom-fs_[\n",
      "      +n-fs_[\n",
      "        +(valla valla NCFS000)\n",
      "      ]\n",
      "    ]\n",
      "  ]\n",
      "  F-term_[\n",
      "    +(. . Fp)\n",
      "  ]\n",
      "]\n",
      "S_[\n",
      "  grup-verb_[\n",
      "    +verb_[\n",
      "      +(Estoy estar VMIP1S0)\n",
      "    ]\n",
      "  ]\n",
      "  parti-flex_[\n",
      "    +parti-fs_[\n",
      "      +(preocupada preocupar VMP00SF)\n",
      "    ]\n",
      "  ]\n",
      "  (, , Fc)\n",
      "  sadv_[\n",
      "    +(quizás quizás RG)\n",
      "  ]\n",
      "  grup-verb_[\n",
      "    morfema-verbal_[\n",
      "      +(se se P00CN00)\n",
      "    ]\n",
      "    +grup-verb_[\n",
      "      +verb_[\n",
      "        +(pierda perder VMSP3S0)\n",
      "      ]\n",
      "    ]\n",
      "  ]\n",
      "  coord_[\n",
      "    +(o o CC)\n",
      "  ]\n",
      "  grup-verb_[\n",
      "    +verb_[\n",
      "      +(ataque atacar VMSP3S0)\n",
      "    ]\n",
      "  ]\n",
      "  grup-sp_[\n",
      "    +prep_[\n",
      "      +(a a SP)\n",
      "    ]\n",
      "    sn_[\n",
      "      +pron-ms_[\n",
      "        +pindef-ms_[\n",
      "          +(alguien alguien PI0CS00)\n",
      "        ]\n",
      "      ]\n",
      "    ]\n",
      "  ]\n",
      "  F-term_[\n",
      "    +(. . Fp)\n",
      "  ]\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "#Análisis sintáctico\n",
    "\n",
    "ls = parser.analyze(ls);\n",
    "for s in ls :\n",
    "    tr = s.get_parse_tree();\n",
    "    printTree(tr, 0);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'      { \"id\":\"1\",\\n        \"tokens\" : [\\n           { \"id\" : \"t1.1\", \"begin\" : \"0\", \"end\" : \"2\", \"form\" : \"El\", \"lemma\" : \"el\", \"tag\" : \"DA0MS0\"},\\n           { \"id\" : \"t1.2\", \"begin\" : \"3\", \"end\" : \"8\", \"form\" : \"perro\", \"lemma\" : \"perro\", \"tag\" : \"NCMS000\", \"wn\" : \"02084071-n\"},\\n           { \"id\" : \"t1.3\", \"begin\" : \"9\", \"end\" : \"11\", \"form\" : \"ha\", \"lemma\" : \"haber\", \"tag\" : \"VAIP3S0\", \"wn\" : \"02603699-v\"},\\n           { \"id\" : \"t1.4\", \"begin\" : \"12\", \"end\" : \"19\", \"form\" : \"saltado\", \"lemma\" : \"saltar\", \"tag\" : \"VMP00SM\", \"wn\" : \"00256369-v\"},\\n           { \"id\" : \"t1.5\", \"begin\" : \"20\", \"end\" : \"22\", \"form\" : \"la\", \"lemma\" : \"el\", \"tag\" : \"DA0FS0\"},\\n           { \"id\" : \"t1.6\", \"begin\" : \"23\", \"end\" : \"28\", \"form\" : \"valla\", \"lemma\" : \"valla\", \"tag\" : \"NCFS000\"},\\n           { \"id\" : \"t1.7\", \"begin\" : \"28\", \"end\" : \"29\", \"form\" : \".\", \"lemma\" : \".\", \"tag\" : \"Fp\"}],\\n        \"constituents\" : [\\n          {\"label\" : \"S\", \"children\" : [\\n            {\"label\" : \"sn\", \"children\" : [\\n              {\"label\" : \"espec-ms\", \"children\" : [\\n                {\"label\" : \"j-ms\", \"head\" : \"1\", \"children\" : [\\n                  {\"leaf\" : \"1\", \"head\" : \"1\", \"token\" : \"t1.1\", \"word\" : \"El\"}\\n                ]}\\n              ]}, \\n              {\"label\" : \"grup-nom-ms\", \"head\" : \"1\", \"children\" : [\\n                {\"label\" : \"n-ms\", \"head\" : \"1\", \"children\" : [\\n                  {\"leaf\" : \"1\", \"head\" : \"1\", \"token\" : \"t1.2\", \"word\" : \"perro\"}\\n                ]}\\n              ]}\\n            ]}, \\n            {\"label\" : \"grup-verb\", \"children\" : [\\n              {\"label\" : \"verb\", \"head\" : \"1\", \"children\" : [\\n                {\"label\" : \"vaux\", \"children\" : [\\n                  {\"leaf\" : \"1\", \"head\" : \"1\", \"token\" : \"t1.3\", \"word\" : \"ha\"}\\n                ]}, \\n                {\"label\" : \"parti\", \"head\" : \"1\", \"children\" : [\\n                  {\"leaf\" : \"1\", \"head\" : \"1\", \"token\" : \"t1.4\", \"word\" : \"saltado\"}\\n                ]}\\n              ]}\\n            ]}, \\n            {\"label\" : \"sn\", \"children\" : [\\n              {\"label\" : \"espec-fs\", \"children\" : [\\n                {\"label\" : \"j-fs\", \"head\" : \"1\", \"children\" : [\\n                  {\"leaf\" : \"1\", \"head\" : \"1\", \"token\" : \"t1.5\", \"word\" : \"la\"}\\n                ]}\\n              ]}, \\n              {\"label\" : \"grup-nom-fs\", \"head\" : \"1\", \"children\" : [\\n                {\"label\" : \"n-fs\", \"head\" : \"1\", \"children\" : [\\n                  {\"leaf\" : \"1\", \"head\" : \"1\", \"token\" : \"t1.6\", \"word\" : \"valla\"}\\n                ]}\\n              ]}\\n            ]}, \\n            {\"label\" : \"F-term\", \"children\" : [\\n              {\"leaf\" : \"1\", \"head\" : \"1\", \"token\" : \"t1.7\", \"word\" : \".\"}\\n            ]}\\n          ]}]}, \\n      { \"id\":\"2\",\\n        \"tokens\" : [\\n           { \"id\" : \"t2.1\", \"begin\" : \"30\", \"end\" : \"35\", \"form\" : \"Estoy\", \"lemma\" : \"estar\", \"tag\" : \"VMIP1S0\", \"wn\" : \"02655135-v\"},\\n           { \"id\" : \"t2.2\", \"begin\" : \"36\", \"end\" : \"46\", \"form\" : \"preocupada\", \"lemma\" : \"preocupar\", \"tag\" : \"VMP00SF\", \"wn\" : \"01765908-v\"},\\n           { \"id\" : \"t2.3\", \"begin\" : \"46\", \"end\" : \"47\", \"form\" : \",\", \"lemma\" : \",\", \"tag\" : \"Fc\"},\\n           { \"id\" : \"t2.4\", \"begin\" : \"48\", \"end\" : \"54\", \"form\" : \"quizás\", \"lemma\" : \"quizás\", \"tag\" : \"RG\"},\\n           { \"id\" : \"t2.5\", \"begin\" : \"55\", \"end\" : \"57\", \"form\" : \"se\", \"lemma\" : \"se\", \"tag\" : \"P00CN00\"},\\n           { \"id\" : \"t2.6\", \"begin\" : \"58\", \"end\" : \"64\", \"form\" : \"pierda\", \"lemma\" : \"perder\", \"tag\" : \"VMSP3S0\", \"wn\" : \"00059769-v\"},\\n           { \"id\" : \"t2.7\", \"begin\" : \"65\", \"end\" : \"66\", \"form\" : \"o\", \"lemma\" : \"o\", \"tag\" : \"CC\"},\\n           { \"id\" : \"t2.8\", \"begin\" : \"67\", \"end\" : \"73\", \"form\" : \"ataque\", \"lemma\" : \"atacar\", \"tag\" : \"VMSP3S0\", \"wn\" : \"00019792-v\"},\\n           { \"id\" : \"t2.9\", \"begin\" : \"74\", \"end\" : \"75\", \"form\" : \"a\", \"lemma\" : \"a\", \"tag\" : \"SP\"},\\n           { \"id\" : \"t2.10\", \"begin\" : \"76\", \"end\" : \"83\", \"form\" : \"alguien\", \"lemma\" : \"alguien\", \"tag\" : \"PI0CS00\"},\\n           { \"id\" : \"t2.11\", \"begin\" : \"83\", \"end\" : \"84\", \"form\" : \".\", \"lemma\" : \".\", \"tag\" : \"Fp\"}],\\n        \"constituents\" : [\\n          {\"label\" : \"S\", \"children\" : [\\n            {\"label\" : \"grup-verb\", \"children\" : [\\n              {\"label\" : \"verb\", \"head\" : \"1\", \"children\" : [\\n                {\"leaf\" : \"1\", \"head\" : \"1\", \"token\" : \"t2.1\", \"word\" : \"Estoy\"}\\n              ]}\\n            ]}, \\n            {\"label\" : \"parti-flex\", \"children\" : [\\n              {\"label\" : \"parti-fs\", \"head\" : \"1\", \"children\" : [\\n                {\"leaf\" : \"1\", \"head\" : \"1\", \"token\" : \"t2.2\", \"word\" : \"preocupada\"}\\n              ]}\\n            ]}, \\n            {\"leaf\" : \"1\", \"token\" : \"t2.3\", \"word\" : \",\"}, \\n            {\"label\" : \"sadv\", \"children\" : [\\n              {\"leaf\" : \"1\", \"head\" : \"1\", \"token\" : \"t2.4\", \"word\" : \"quizás\"}\\n            ]}, \\n            {\"label\" : \"grup-verb\", \"children\" : [\\n              {\"label\" : \"morfema-verbal\", \"children\" : [\\n                {\"leaf\" : \"1\", \"head\" : \"1\", \"token\" : \"t2.5\", \"word\" : \"se\"}\\n              ]}, \\n              {\"label\" : \"grup-verb\", \"head\" : \"1\", \"children\" : [\\n                {\"label\" : \"verb\", \"head\" : \"1\", \"children\" : [\\n                  {\"leaf\" : \"1\", \"head\" : \"1\", \"token\" : \"t2.6\", \"word\" : \"pierda\"}\\n                ]}\\n              ]}\\n            ]}, \\n            {\"label\" : \"coord\", \"children\" : [\\n              {\"leaf\" : \"1\", \"head\" : \"1\", \"token\" : \"t2.7\", \"word\" : \"o\"}\\n            ]}, \\n            {\"label\" : \"grup-verb\", \"children\" : [\\n              {\"label\" : \"verb\", \"head\" : \"1\", \"children\" : [\\n                {\"leaf\" : \"1\", \"head\" : \"1\", \"token\" : \"t2.8\", \"word\" : \"ataque\"}\\n              ]}\\n            ]}, \\n            {\"label\" : \"grup-sp\", \"children\" : [\\n              {\"label\" : \"prep\", \"head\" : \"1\", \"children\" : [\\n                {\"leaf\" : \"1\", \"head\" : \"1\", \"token\" : \"t2.9\", \"word\" : \"a\"}\\n              ]}, \\n              {\"label\" : \"sn\", \"children\" : [\\n                {\"label\" : \"pron-ms\", \"head\" : \"1\", \"children\" : [\\n                  {\"label\" : \"pindef-ms\", \"head\" : \"1\", \"children\" : [\\n                    {\"leaf\" : \"1\", \"head\" : \"1\", \"token\" : \"t2.10\", \"word\" : \"alguien\"}\\n                  ]}\\n                ]}\\n              ]}\\n            ]}, \\n            {\"label\" : \"F-term\", \"children\" : [\\n              {\"leaf\" : \"1\", \"head\" : \"1\", \"token\" : \"t2.11\", \"word\" : \".\"}\\n            ]}\\n          ]}]}'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = freeling.output_json()\n",
    "output.PrintResults(ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<sentence id=\"1\">\\n  <token id=\"t1.1\" begin=\"0\" end=\"2\" form=\"El\" lemma=\"el\" tag=\"DA0MS0\" >\\n  </token>\\n  <token id=\"t1.2\" begin=\"3\" end=\"8\" form=\"perro\" lemma=\"perro\" tag=\"NCMS000\" wn=\"02084071-n\" >\\n  </token>\\n  <token id=\"t1.3\" begin=\"9\" end=\"11\" form=\"ha\" lemma=\"haber\" tag=\"VAIP3S0\" wn=\"02603699-v\" >\\n  </token>\\n  <token id=\"t1.4\" begin=\"12\" end=\"19\" form=\"saltado\" lemma=\"saltar\" tag=\"VMP00SM\" wn=\"00256369-v\" >\\n  </token>\\n  <token id=\"t1.5\" begin=\"20\" end=\"22\" form=\"la\" lemma=\"el\" tag=\"DA0FS0\" >\\n  </token>\\n  <token id=\"t1.6\" begin=\"23\" end=\"28\" form=\"valla\" lemma=\"valla\" tag=\"NCFS000\" >\\n  </token>\\n  <token id=\"t1.7\" begin=\"28\" end=\"29\" form=\".\" lemma=\".\" tag=\"Fp\" >\\n  </token>\\n  <constituents>\\n    <node label=\"S\" >\\n      <node label=\"sn\" >\\n        <node label=\"espec-ms\" >\\n          <node head=\"1\" label=\"j-ms\" >\\n            <node leaf=\"1\" head=\"1\" token=\"t1.1\" word=\"El\" />\\n          </node>\\n        </node>\\n        <node head=\"1\" label=\"grup-nom-ms\" >\\n          <node head=\"1\" label=\"n-ms\" >\\n            <node leaf=\"1\" head=\"1\" token=\"t1.2\" word=\"perro\" />\\n          </node>\\n        </node>\\n      </node>\\n      <node label=\"grup-verb\" >\\n        <node head=\"1\" label=\"verb\" >\\n          <node label=\"vaux\" >\\n            <node leaf=\"1\" head=\"1\" token=\"t1.3\" word=\"ha\" />\\n          </node>\\n          <node head=\"1\" label=\"parti\" >\\n            <node leaf=\"1\" head=\"1\" token=\"t1.4\" word=\"saltado\" />\\n          </node>\\n        </node>\\n      </node>\\n      <node label=\"sn\" >\\n        <node label=\"espec-fs\" >\\n          <node head=\"1\" label=\"j-fs\" >\\n            <node leaf=\"1\" head=\"1\" token=\"t1.5\" word=\"la\" />\\n          </node>\\n        </node>\\n        <node head=\"1\" label=\"grup-nom-fs\" >\\n          <node head=\"1\" label=\"n-fs\" >\\n            <node leaf=\"1\" head=\"1\" token=\"t1.6\" word=\"valla\" />\\n          </node>\\n        </node>\\n      </node>\\n      <node label=\"F-term\" >\\n        <node leaf=\"1\" head=\"1\" token=\"t1.7\" word=\".\" />\\n      </node>\\n    </node>\\n  </constituents>\\n</sentence>\\n<sentence id=\"2\">\\n  <token id=\"t2.1\" begin=\"30\" end=\"35\" form=\"Estoy\" lemma=\"estar\" tag=\"VMIP1S0\" wn=\"02655135-v\" >\\n  </token>\\n  <token id=\"t2.2\" begin=\"36\" end=\"46\" form=\"preocupada\" lemma=\"preocupar\" tag=\"VMP00SF\" wn=\"01765908-v\" >\\n  </token>\\n  <token id=\"t2.3\" begin=\"46\" end=\"47\" form=\",\" lemma=\",\" tag=\"Fc\" >\\n  </token>\\n  <token id=\"t2.4\" begin=\"48\" end=\"54\" form=\"quizás\" lemma=\"quizás\" tag=\"RG\" >\\n  </token>\\n  <token id=\"t2.5\" begin=\"55\" end=\"57\" form=\"se\" lemma=\"se\" tag=\"P00CN00\" >\\n  </token>\\n  <token id=\"t2.6\" begin=\"58\" end=\"64\" form=\"pierda\" lemma=\"perder\" tag=\"VMSP3S0\" wn=\"00059769-v\" >\\n  </token>\\n  <token id=\"t2.7\" begin=\"65\" end=\"66\" form=\"o\" lemma=\"o\" tag=\"CC\" >\\n  </token>\\n  <token id=\"t2.8\" begin=\"67\" end=\"73\" form=\"ataque\" lemma=\"atacar\" tag=\"VMSP3S0\" wn=\"00019792-v\" >\\n  </token>\\n  <token id=\"t2.9\" begin=\"74\" end=\"75\" form=\"a\" lemma=\"a\" tag=\"SP\" >\\n  </token>\\n  <token id=\"t2.10\" begin=\"76\" end=\"83\" form=\"alguien\" lemma=\"alguien\" tag=\"PI0CS00\" >\\n  </token>\\n  <token id=\"t2.11\" begin=\"83\" end=\"84\" form=\".\" lemma=\".\" tag=\"Fp\" >\\n  </token>\\n  <constituents>\\n    <node label=\"S\" >\\n      <node label=\"grup-verb\" >\\n        <node head=\"1\" label=\"verb\" >\\n          <node leaf=\"1\" head=\"1\" token=\"t2.1\" word=\"Estoy\" />\\n        </node>\\n      </node>\\n      <node label=\"parti-flex\" >\\n        <node head=\"1\" label=\"parti-fs\" >\\n          <node leaf=\"1\" head=\"1\" token=\"t2.2\" word=\"preocupada\" />\\n        </node>\\n      </node>\\n      <node leaf=\"1\" token=\"t2.3\" word=\",\" />\\n      <node label=\"sadv\" >\\n        <node leaf=\"1\" head=\"1\" token=\"t2.4\" word=\"quizás\" />\\n      </node>\\n      <node label=\"grup-verb\" >\\n        <node label=\"morfema-verbal\" >\\n          <node leaf=\"1\" head=\"1\" token=\"t2.5\" word=\"se\" />\\n        </node>\\n        <node head=\"1\" label=\"grup-verb\" >\\n          <node head=\"1\" label=\"verb\" >\\n            <node leaf=\"1\" head=\"1\" token=\"t2.6\" word=\"pierda\" />\\n          </node>\\n        </node>\\n      </node>\\n      <node label=\"coord\" >\\n        <node leaf=\"1\" head=\"1\" token=\"t2.7\" word=\"o\" />\\n      </node>\\n      <node label=\"grup-verb\" >\\n        <node head=\"1\" label=\"verb\" >\\n          <node leaf=\"1\" head=\"1\" token=\"t2.8\" word=\"ataque\" />\\n        </node>\\n      </node>\\n      <node label=\"grup-sp\" >\\n        <node head=\"1\" label=\"prep\" >\\n          <node leaf=\"1\" head=\"1\" token=\"t2.9\" word=\"a\" />\\n        </node>\\n        <node label=\"sn\" >\\n          <node head=\"1\" label=\"pron-ms\" >\\n            <node head=\"1\" label=\"pindef-ms\" >\\n              <node leaf=\"1\" head=\"1\" token=\"t2.10\" word=\"alguien\" />\\n            </node>\\n          </node>\\n        </node>\\n      </node>\\n      <node label=\"F-term\" >\\n        <node leaf=\"1\" head=\"1\" token=\"t2.11\" word=\".\" />\\n      </node>\\n    </node>\\n  </constituents>\\n</sentence>\\n'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = freeling.output_xml()\n",
    "output.PrintResults(ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grup-verb/top/(saltado saltar VMP00SM) [\n",
      "  vaux/aux/(ha haber VAIP3S0)\n",
      "  sn/subj/(perro perro NCMS000) [\n",
      "    espec-ms/spec/(El el DA0MS0)\n",
      "  ]\n",
      "  sn/dobj/(valla valla NCFS000) [\n",
      "    espec-fs/spec/(la el DA0FS0)\n",
      "  ]\n",
      "  F-term/punc/(. . Fp)\n",
      "]\n",
      "coor-vb/top/(o o CC) [\n",
      "  grup-verb/coor/(Estoy estar VMIP1S0) [\n",
      "    subord-part/attr/(preocupada preocupar VMP00SF)\n",
      "  ]\n",
      "  Fc/punc/(, , Fc)\n",
      "  grup-verb/coor/(pierda perder VMSP3S0) [\n",
      "    morfema-verbal/mphes/(se se P00CN00)\n",
      "    sadv/adjt/(quizás quizás RG)\n",
      "  ]\n",
      "  grup-verb/coor/(ataque atacar VMSP3S0) [\n",
      "    grup-sp/adjt/(a a SP) [\n",
      "      sn/comp/(alguien alguien PI0CS00)\n",
      "    ]\n",
      "  ]\n",
      "  F-term/punc/(. . Fp)\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "#Análisis de dependencias\n",
    "\n",
    "ls = dep.analyze(ls);\n",
    "\n",
    "for s in ls:\n",
    "    dp = s.get_dep_tree();\n",
    "    printDepTree(dp, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<sentence id=\"1\">\\n  <token id=\"t1.1\" begin=\"0\" end=\"2\" form=\"El\" lemma=\"el\" tag=\"DA0MS0\" >\\n  </token>\\n  <token id=\"t1.2\" begin=\"3\" end=\"8\" form=\"perro\" lemma=\"perro\" tag=\"NCMS000\" wn=\"02084071-n\" >\\n  </token>\\n  <token id=\"t1.3\" begin=\"9\" end=\"11\" form=\"ha\" lemma=\"haber\" tag=\"VAIP3S0\" wn=\"02603699-v\" >\\n  </token>\\n  <token id=\"t1.4\" begin=\"12\" end=\"19\" form=\"saltado\" lemma=\"saltar\" tag=\"VMP00SM\" wn=\"00256369-v\" >\\n  </token>\\n  <token id=\"t1.5\" begin=\"20\" end=\"22\" form=\"la\" lemma=\"el\" tag=\"DA0FS0\" >\\n  </token>\\n  <token id=\"t1.6\" begin=\"23\" end=\"28\" form=\"valla\" lemma=\"valla\" tag=\"NCFS000\" >\\n  </token>\\n  <token id=\"t1.7\" begin=\"28\" end=\"29\" form=\".\" lemma=\".\" tag=\"Fp\" >\\n  </token>\\n  <constituents>\\n    <node head=\"1\" label=\"grup-verb\" >\\n      <node label=\"sn\" >\\n        <node label=\"espec-ms\" >\\n          <node head=\"1\" label=\"j-ms\" >\\n            <node leaf=\"1\" head=\"1\" token=\"t1.1\" word=\"El\" />\\n          </node>\\n        </node>\\n        <node head=\"1\" label=\"grup-nom-ms\" >\\n          <node head=\"1\" label=\"n-ms\" >\\n            <node leaf=\"1\" head=\"1\" token=\"t1.2\" word=\"perro\" />\\n          </node>\\n        </node>\\n      </node>\\n      <node head=\"1\" label=\"verb\" >\\n        <node label=\"vaux\" >\\n          <node leaf=\"1\" head=\"1\" token=\"t1.3\" word=\"ha\" />\\n        </node>\\n        <node head=\"1\" label=\"parti\" >\\n          <node leaf=\"1\" head=\"1\" token=\"t1.4\" word=\"saltado\" />\\n        </node>\\n      </node>\\n      <node label=\"sn\" >\\n        <node label=\"espec-fs\" >\\n          <node head=\"1\" label=\"j-fs\" >\\n            <node leaf=\"1\" head=\"1\" token=\"t1.5\" word=\"la\" />\\n          </node>\\n        </node>\\n        <node head=\"1\" label=\"grup-nom-fs\" >\\n          <node head=\"1\" label=\"n-fs\" >\\n            <node leaf=\"1\" head=\"1\" token=\"t1.6\" word=\"valla\" />\\n          </node>\\n        </node>\\n      </node>\\n      <node label=\"F-term\" >\\n        <node leaf=\"1\" head=\"1\" token=\"t1.7\" word=\".\" />\\n      </node>\\n    </node>\\n  </constituents>\\n  <dependencies>\\n    <depnode token=\"t1.4\" function=\"top\" word=\"saltado\" >\\n      <depnode token=\"t1.3\" function=\"aux\" word=\"ha\" />\\n      <depnode token=\"t1.2\" function=\"subj\" word=\"perro\" >\\n        <depnode token=\"t1.1\" function=\"spec\" word=\"El\" />\\n      </depnode>\\n      <depnode token=\"t1.6\" function=\"dobj\" word=\"valla\" >\\n        <depnode token=\"t1.5\" function=\"spec\" word=\"la\" />\\n      </depnode>\\n      <depnode token=\"t1.7\" function=\"punc\" word=\".\" />\\n    </depnode>\\n  </dependencies>\\n</sentence>\\n<sentence id=\"2\">\\n  <token id=\"t2.1\" begin=\"30\" end=\"35\" form=\"Estoy\" lemma=\"estar\" tag=\"VMIP1S0\" wn=\"02655135-v\" >\\n  </token>\\n  <token id=\"t2.2\" begin=\"36\" end=\"46\" form=\"preocupada\" lemma=\"preocupar\" tag=\"VMP00SF\" wn=\"01765908-v\" >\\n  </token>\\n  <token id=\"t2.3\" begin=\"46\" end=\"47\" form=\",\" lemma=\",\" tag=\"Fc\" >\\n  </token>\\n  <token id=\"t2.4\" begin=\"48\" end=\"54\" form=\"quizás\" lemma=\"quizás\" tag=\"RG\" >\\n  </token>\\n  <token id=\"t2.5\" begin=\"55\" end=\"57\" form=\"se\" lemma=\"se\" tag=\"P00CN00\" >\\n  </token>\\n  <token id=\"t2.6\" begin=\"58\" end=\"64\" form=\"pierda\" lemma=\"perder\" tag=\"VMSP3S0\" wn=\"00059769-v\" >\\n  </token>\\n  <token id=\"t2.7\" begin=\"65\" end=\"66\" form=\"o\" lemma=\"o\" tag=\"CC\" >\\n  </token>\\n  <token id=\"t2.8\" begin=\"67\" end=\"73\" form=\"ataque\" lemma=\"atacar\" tag=\"VMSP3S0\" wn=\"00019792-v\" >\\n  </token>\\n  <token id=\"t2.9\" begin=\"74\" end=\"75\" form=\"a\" lemma=\"a\" tag=\"SP\" >\\n  </token>\\n  <token id=\"t2.10\" begin=\"76\" end=\"83\" form=\"alguien\" lemma=\"alguien\" tag=\"PI0CS00\" >\\n  </token>\\n  <token id=\"t2.11\" begin=\"83\" end=\"84\" form=\".\" lemma=\".\" tag=\"Fp\" >\\n  </token>\\n  <constituents>\\n    <node head=\"1\" label=\"coor-vb\" >\\n      <node label=\"grup-verb\" >\\n        <node head=\"1\" label=\"verb\" >\\n          <node leaf=\"1\" head=\"1\" token=\"t2.1\" word=\"Estoy\" />\\n        </node>\\n        <node label=\"subord-part\" >\\n          <node head=\"1\" label=\"parti-fs\" >\\n            <node leaf=\"1\" head=\"1\" token=\"t2.2\" word=\"preocupada\" />\\n          </node>\\n        </node>\\n      </node>\\n      <node label=\"Fc\" >\\n        <node leaf=\"1\" head=\"1\" token=\"t2.3\" word=\",\" />\\n      </node>\\n      <node label=\"grup-verb\" >\\n        <node label=\"sadv\" >\\n          <node leaf=\"1\" head=\"1\" token=\"t2.4\" word=\"quizás\" />\\n        </node>\\n        <node label=\"morfema-verbal\" >\\n          <node leaf=\"1\" head=\"1\" token=\"t2.5\" word=\"se\" />\\n        </node>\\n        <node head=\"1\" label=\"grup-verb\" >\\n          <node head=\"1\" label=\"verb\" >\\n            <node leaf=\"1\" head=\"1\" token=\"t2.6\" word=\"pierda\" />\\n          </node>\\n        </node>\\n      </node>\\n      <node leaf=\"1\" head=\"1\" token=\"t2.7\" word=\"o\" />\\n      <node label=\"grup-verb\" >\\n        <node head=\"1\" label=\"verb\" >\\n          <node leaf=\"1\" head=\"1\" token=\"t2.8\" word=\"ataque\" />\\n        </node>\\n        <node label=\"grup-sp\" >\\n          <node head=\"1\" label=\"prep\" >\\n            <node leaf=\"1\" head=\"1\" token=\"t2.9\" word=\"a\" />\\n          </node>\\n          <node label=\"sn\" >\\n            <node head=\"1\" label=\"pron-ms\" >\\n              <node head=\"1\" label=\"pindef-ms\" >\\n                <node leaf=\"1\" head=\"1\" token=\"t2.10\" word=\"alguien\" />\\n              </node>\\n            </node>\\n          </node>\\n        </node>\\n      </node>\\n      <node label=\"F-term\" >\\n        <node leaf=\"1\" head=\"1\" token=\"t2.11\" word=\".\" />\\n      </node>\\n    </node>\\n  </constituents>\\n  <dependencies>\\n    <depnode token=\"t2.7\" function=\"top\" word=\"o\" >\\n      <depnode token=\"t2.1\" function=\"coor\" word=\"Estoy\" >\\n        <depnode token=\"t2.2\" function=\"attr\" word=\"preocupada\" />\\n      </depnode>\\n      <depnode token=\"t2.3\" function=\"punc\" word=\",\" />\\n      <depnode token=\"t2.6\" function=\"coor\" word=\"pierda\" >\\n        <depnode token=\"t2.5\" function=\"mphes\" word=\"se\" />\\n        <depnode token=\"t2.4\" function=\"adjt\" word=\"quizás\" />\\n      </depnode>\\n      <depnode token=\"t2.8\" function=\"coor\" word=\"ataque\" >\\n        <depnode token=\"t2.9\" function=\"adjt\" word=\"a\" >\\n          <depnode token=\"t2.10\" function=\"comp\" word=\"alguien\" />\\n        </depnode>\\n      </depnode>\\n      <depnode token=\"t2.11\" function=\"punc\" word=\".\" />\\n    </depnode>\\n  </dependencies>\\n</sentence>\\n'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = freeling.output_xml()\n",
    "output.PrintResults(ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El el DA0MS0 \n",
      "perro perro NCMS000 02084071-n:0/10539715-n:0\n",
      "ha haber VAIP3S0 02603699-v:0/02655135-v:0\n",
      "saltado saltar VMP00SM 00256369-v:0/00616498-v:0/01236941-v:0/01892608-v:0/01910373-v:0/01963942-v:0/01965654-v:0/02081946-v:0/02094922-v:0/02095060-v:0/02095211-v:0\n",
      "la el DA0FS0 \n",
      "valla valla NCFS000 \n",
      ". . Fp \n",
      "\n",
      "+grup-verb_[\n",
      "  sn_[\n",
      "    espec-ms_[\n",
      "      +j-ms_[\n",
      "        +(El el DA0MS0)\n",
      "      ]\n",
      "    ]\n",
      "    +grup-nom-ms_[\n",
      "      +n-ms_[\n",
      "        +(perro perro NCMS000)\n",
      "      ]\n",
      "    ]\n",
      "  ]\n",
      "  +verb_[\n",
      "    vaux_[\n",
      "      +(ha haber VAIP3S0)\n",
      "    ]\n",
      "    +parti_[\n",
      "      +(saltado saltar VMP00SM)\n",
      "    ]\n",
      "  ]\n",
      "  sn_[\n",
      "    espec-fs_[\n",
      "      +j-fs_[\n",
      "        +(la el DA0FS0)\n",
      "      ]\n",
      "    ]\n",
      "    +grup-nom-fs_[\n",
      "      +n-fs_[\n",
      "        +(valla valla NCFS000)\n",
      "      ]\n",
      "    ]\n",
      "  ]\n",
      "  F-term_[\n",
      "    +(. . Fp)\n",
      "  ]\n",
      "]\n",
      "grup-verb/top/(saltado saltar VMP00SM) [\n",
      "  vaux/aux/(ha haber VAIP3S0)\n",
      "  sn/subj/(perro perro NCMS000) [\n",
      "    espec-ms/spec/(El el DA0MS0)\n",
      "  ]\n",
      "  sn/dobj/(valla valla NCFS000) [\n",
      "    espec-fs/spec/(la el DA0FS0)\n",
      "  ]\n",
      "  F-term/punc/(. . Fp)\n",
      "]\n",
      "Estoy estar VMIP1S0 02655135-v:0/02729963-v:0\n",
      "preocupada preocupar VMP00SF 01765908-v:0/01767163-v:0/01783394-v:0/02678438-v:0\n",
      ", , Fc \n",
      "quizás quizás RG \n",
      "se se P00CN00 \n",
      "pierda perder VMSP3S0 00059769-v:0/01099592-v:0/01113806-v:0/02022659-v:0/02127853-v:0/02197091-v:0/02287618-v:0/02287789-v:0/02288155-v:0/02288828-v:0/02303331-v:0\n",
      "o o CC \n",
      "ataque atacar VMSP3S0 00019792-v:0/00862683-v:0/01118449-v:0/01119169-v:0/01120069-v:0\n",
      "a a SP \n",
      "alguien alguien PI0CS00 \n",
      ". . Fp \n",
      "\n",
      "+coor-vb_[\n",
      "  grup-verb_[\n",
      "    +verb_[\n",
      "      +(Estoy estar VMIP1S0)\n",
      "    ]\n",
      "    subord-part_[\n",
      "      +parti-fs_[\n",
      "        +(preocupada preocupar VMP00SF)\n",
      "      ]\n",
      "    ]\n",
      "  ]\n",
      "  Fc_[\n",
      "    +(, , Fc)\n",
      "  ]\n",
      "  grup-verb_[\n",
      "    sadv_[\n",
      "      +(quizás quizás RG)\n",
      "    ]\n",
      "    morfema-verbal_[\n",
      "      +(se se P00CN00)\n",
      "    ]\n",
      "    +grup-verb_[\n",
      "      +verb_[\n",
      "        +(pierda perder VMSP3S0)\n",
      "      ]\n",
      "    ]\n",
      "  ]\n",
      "  +(o o CC)\n",
      "  grup-verb_[\n",
      "    +verb_[\n",
      "      +(ataque atacar VMSP3S0)\n",
      "    ]\n",
      "    grup-sp_[\n",
      "      +prep_[\n",
      "        +(a a SP)\n",
      "      ]\n",
      "      sn_[\n",
      "        +pron-ms_[\n",
      "          +pindef-ms_[\n",
      "            +(alguien alguien PI0CS00)\n",
      "          ]\n",
      "        ]\n",
      "      ]\n",
      "    ]\n",
      "  ]\n",
      "  F-term_[\n",
      "    +(. . Fp)\n",
      "  ]\n",
      "]\n",
      "coor-vb/top/(o o CC) [\n",
      "  grup-verb/coor/(Estoy estar VMIP1S0) [\n",
      "    subord-part/attr/(preocupada preocupar VMP00SF)\n",
      "  ]\n",
      "  Fc/punc/(, , Fc)\n",
      "  grup-verb/coor/(pierda perder VMSP3S0) [\n",
      "    morfema-verbal/mphes/(se se P00CN00)\n",
      "    sadv/adjt/(quizás quizás RG)\n",
      "  ]\n",
      "  grup-verb/coor/(ataque atacar VMSP3S0) [\n",
      "    grup-sp/adjt/(a a SP) [\n",
      "      sn/comp/(alguien alguien PI0CS00)\n",
      "    ]\n",
      "  ]\n",
      "  F-term/punc/(. . Fp)\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "# todo junto\n",
    "\n",
    "l = tk.tokenize(text);\n",
    "ls = sp.split(sid,l,False);\n",
    "\n",
    "ls = mf.analyze(ls);\n",
    "ls = tg.analyze(ls);\n",
    "ls = sen.analyze(ls);\n",
    "ls = parser.analyze(ls);\n",
    "ls = dep.analyze(ls);\n",
    "\n",
    "## output results\n",
    "for s in ls :\n",
    "   ws = s.get_words();\n",
    "   for w in ws :\n",
    "      print(w.get_form()+\" \"+w.get_lemma()+\" \"+w.get_tag()+\" \"+w.get_senses_string());\n",
    "   print (\"\");\n",
    "\n",
    "   tr = s.get_parse_tree();\n",
    "   printTree(tr, 0);\n",
    "\n",
    "   dp = s.get_dep_tree();\n",
    "   printDepTree(dp, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
